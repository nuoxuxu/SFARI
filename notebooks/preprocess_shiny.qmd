# Preparation

```{python}
#| label: import-python
import polars as pl
from src.single_cell import SingleCell
from src.utils import read_gtf
import numpy as np
import polars.selectors as cs
```

```{python}
#| label: read-gencode_V39

gencode_V39 = read_gtf("/Users/xunuo/Genomic_references/GENCODE/gencode.v39.annotation.gtf", ["gene_name", "transcript_id", "gene_id"]).filter(pl.col("feature")=="exon")
```

```{python}
#| label: define-functions

def read_refmap(file):
    out = pl.read_csv(file, separator="\t")\
    .filter(pl.col("class_code")=="=")\
    .with_columns(
        pl.col("qry_id_list").str.split(",").map_elements(lambda s: [e.split("|")[1] for e in s], return_dtype=pl.List(pl.String)).alias("qry_id_list"))\
    .explode("qry_id_list")\
    .select(["qry_id_list", "ref_id"])\
    .rename({"qry_id_list": "transcript_id"})
    return out
```

# Preprocess TALON GTF

Since `talon.gtf` is in hg19, we need to lift it over to hg38

```{bash}
#| label: liftover

curl -L https://hgdownload.cse.ucsc.edu/goldenpath/hg19/liftOver/hg19ToHg38.over.chain.gz -o hg19ToHg38.over.chain.gz

CrossMap gff proc/hg19ToHg38.over.chain /Users/xunuo/projects/Dev_Brain_IsoSeq/data/cp_vz_0.75_min_7_recovery_talon.gtf proc/cp_vz_0.75_min_7_recovery_talon_hg38.gtf
```

Since `talon.gtf` is mapped to Gencode v33, we need to get a mapping from TALON transcript IDs to ENST IDs in Gencode v39

```{bash}
#| label: gffcompare

gffcompare -r /Users/xunuo/Genomic_references/GENCODE/gencode.v39.annotation.gtf proc/cp_vz_0.75_min_7_recovery_talon_hg38.gtf -o proc/TALON_GENCODE_V39
```

```{python}
#| label: TALON_ID_to_GENCODE_V39

TALON_ID_to_GENCODE_V39 = read_refmap("proc/TALON_GENCODE_V39.cp_vz_0.75_min_7_recovery_talon_hg38.gtf.refmap")
```

Since the mappping between transcript_id and ref_id is not injective, we need to identify transcripts that are not uniquely mapped to a ref_id and remove them. It turns out that most transcript_id that are not uniquely mapped to a ref_id at least maps to one ref_id that matches transcript_id exactly (the version numbers could be different), so we decided to discard the other match and treat these cases as one-to-one. The transcript_id that are mapped to more than one ref_id where none of the matching ref_id matches the transcript_id are removed.

```{python}
#| label: n_transcripts_removed

n_transcripts_removed = TALON_ID_to_GENCODE_V39\
    .filter(pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39.group_by("transcript_id").len().filter(pl.col("len")>1)["transcript_id"]))\
    .with_columns(
        pl.col("transcript_id").map_elements(lambda s: s.split("_")[0].split(".")[0], return_dtype=pl.String),
        pl.col("ref_id").map_elements(lambda s: s.split(".")[0], return_dtype=pl.String)
    )\
    .with_columns(
        is_same = (pl.col("transcript_id") == pl.col("ref_id"))
    )\
    .with_columns(
        pl.col("is_same").cast(pl.Int16)
    )\
    .group_by("transcript_id").agg(
        pl.col("is_same").sum().alias("is_same")
    ).filter(pl.col("is_same")==0).shape[0]

print(f"{n_transcripts_removed} transcripts will be removed because they are not uniquely mapped to a ref_id and none of the matching ref_id matches the transcript_id")    
```

Make sure TALON_ID_to_GENCODE_V39 is injective

```{python}
#| label: keep-only-one-to-one-mappings-TALON_ID_to_GENCODE_V39

one_to_one = TALON_ID_to_GENCODE_V39\
    .filter(pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39.group_by("transcript_id").len().filter(pl.col("len")==1)["transcript_id"]))

one_to_many = TALON_ID_to_GENCODE_V39\
    .filter(pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39.group_by("transcript_id").len().filter(pl.col("len")>1)["transcript_id"]))\
    .with_columns(
        is_same = (pl.col("transcript_id").map_elements(lambda s: s.split("_")[0].split(".")[0], return_dtype=pl.String) ==  pl.col("ref_id").map_elements(lambda s: s.split(".")[0], return_dtype=pl.String))
    )\
    .with_columns(
        pl.col("is_same").cast(pl.Int16)
    )\
    .filter(
        pl.col("is_same") == 1
    ).drop("is_same")

TALON_ID_to_GENCODE_V39 = pl.concat([one_to_one, one_to_many], how="vertical")
```

```{python}
#| label: import-TALON_gtf

TALON_gtf = read_gtf("proc/cp_vz_0.75_min_7_recovery_talon_hg38.gtf", ["gene_name", "transcript_id", "gene_id"])\
    .filter(
        pl.col("feature")=="exon",
        pl.col("gene_name").str.starts_with("TALON").not_()
    )
```

```{python}
#| label: write-TALON_not_in_GENCODE

TALON_gtf\
    .filter(
        (pl.col("transcript_id").str.starts_with("TALON")) & (pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39["transcript_id"]).not_())
    )\
    .with_columns(
        attributes = pl.lit('gene_name "') + pl.col("gene_name") + pl.lit('"; transcript_id "') + pl.col("transcript_id") + pl.lit('"; gene_id "') + pl.col("gene_id") + pl.lit('";')
    )\
    .drop("gene_name", "transcript_id", "gene_id")\
    .write_csv("proc/TALON_not_in_GENCODE.gtf", separator="\t", quote_style="never", include_header=False)    
```

# Preprocess SFARI GTF

```{python}
#| label: import-SFARI_gff

lr_bulk = SingleCell("results/long_read/pbid_filtered.h5ad")

SFARI_gff = read_gtf(
    "/Users/xunuo/projects/SFARI/results/long_read/merged_collapsed.sorted.gff", 
    ["transcript_id"])\
    .rename({"transcript_id": "pbid"})\
    .filter(pl.col("feature")=="exon")\
    .join(lr_bulk.var["pbid", "associated_transcript", "associated_gene"], on="pbid", how="left")\
    .filter(pl.col("associated_gene").cast(pl.String).str.starts_with("novelGene").not_())\
    .with_columns(
        pl.col("associated_transcript").cast(pl.String)
        )
```

```{python}
#| label: write-SFARI_not_in_GENCODE

SFARI_gff\
    .filter(pl.col("associated_transcript") == "novel")\
    .with_columns(
        attributes = pl.lit('gene_id "') + pl.col("associated_gene") + pl.lit('"; transcript_id "') + pl.col("pbid") + pl.lit('";')
    )\
    .drop("pbid", "associated_gene", "associated_transcript")\
    .write_csv("proc/SFARI_not_in_GENCODE.gtf", separator="\t", quote_style="never", include_header=False)
```

Get a mapping from SFARI pbid to TALON transcript ID

```{bash}
#| label: gffcompare

gffcompare -r proc/TALON_not_in_GENCODE.gtf proc/SFARI_not_in_GENCODE.gtf -o proc/SFARI_TALON
```

```{python}
#| label: get-PBID_to_TALON_ID

PBID_to_TALON_ID = read_refmap("proc/SFARI_TALON.SFARI_not_in_GENCODE.gtf.refmap")
```

```{python}
#| label: get-combined_gtf

GENCODE_ID_union = np.union1d(
    TALON_ID_to_GENCODE_V39["ref_id"].unique().to_numpy().reshape(-1),
    SFARI_gff.filter(pl.col("associated_transcript").is_in(["novel"]).not_()).select(["associated_transcript"]).unique().to_numpy().reshape(-1)
    )

GENCODE_part = gencode_V39\
    .filter(pl.col("transcript_id").is_in(GENCODE_ID_union))\
    .select(
        [
            "seqname",
            "start",
            "end",
            "strand",
            "gene_name",
            "transcript_id"
        ]
    )

# TALON IDs that are not in GENCODE

TALON_part = TALON_gtf.filter((pl.col("transcript_id").str.starts_with("TALON")) & (pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39["transcript_id"]).not_()))\
    .select(
        [
            "seqname",
            "start",
            "end",
            "strand",
            "gene_name",
            "transcript_id"
        ]
    )

# novel PBIDs that are not in TALON

SFARI_part = SFARI_gff\
    .filter(pl.col("associated_transcript").is_in(["novel"]))\
    .filter(pl.col("pbid").is_in(PBID_to_TALON_ID["pbid"]).not_())\
    .select(
    [
        "seqname",
        "start",
        "end",
        "strand",
        "associated_gene",
        "pbid"
    ])\
    .rename({"associated_gene": "gene_name", "pbid": "transcript_id"})\
    .cast({"gene_name": pl.String})

combined_gtf = pl.concat([GENCODE_part, TALON_part, SFARI_part], how="vertical")    
```

```{python}
#| label: add-dataset-label

GENCODE_unique_to_TALON = np.setdiff1d(
    TALON_ID_to_GENCODE_V39["ref_id"].unique().to_numpy().reshape(-1),
    SFARI_gff.filter(pl.col("associated_transcript").is_in(["novel"]).not_()).select(["associated_transcript"]).unique().to_numpy().reshape(-1)
)

GENCODE_unique_to_SFARI = np.setdiff1d(
    SFARI_gff.filter(pl.col("associated_transcript").is_in(["novel"]).not_()).select(["associated_transcript"]).unique().to_numpy().reshape(-1),
    TALON_ID_to_GENCODE_V39["ref_id"].unique().to_numpy().reshape(-1)
)

GENCODE_overlapped = np.intersect1d(
    TALON_ID_to_GENCODE_V39["ref_id"].unique().to_numpy().reshape(-1),
    SFARI_gff.filter(pl.col("associated_transcript").is_in(["novel"]).not_()).select(["associated_transcript"]).unique().to_numpy().reshape(-1)
)

TALON_transcripts = TALON_gtf\
    .filter(pl.col("transcript_id").str.starts_with("TALON"))\
    .filter(pl.col("transcript_id").is_in(PBID_to_TALON_ID["ref_id"]).not_())["transcript_id"].unique().to_numpy().reshape(-1)

SFARI_transcripts = SFARI_gff\
    .filter(pl.col("associated_transcript").is_in(["novel"]))\
    .filter(pl.col("pbid").is_in(PBID_to_TALON_ID["pbid"]).not_())["pbid"].unique().to_numpy().reshape(-1)

unique_to_TALON = np.union1d(GENCODE_unique_to_TALON, TALON_transcripts)

unique_to_SFARI = np.union1d(GENCODE_unique_to_SFARI, SFARI_transcripts)

overlapped = np.hstack([GENCODE_overlapped, PBID_to_TALON_ID["ref_id"].unique().to_numpy().reshape(-1)])

dataset_label = pl.concat(
    [
        pl.DataFrame({
            "transcript_id": unique_to_TALON,
            "dataset": np.repeat("Patowary et al.", len(unique_to_TALON))
        }),
        pl.DataFrame({
            "transcript_id": unique_to_SFARI,
            "dataset": np.repeat("SFARI", len(unique_to_SFARI))
        }),
        pl.DataFrame({
            "transcript_id": overlapped,
            "dataset": np.repeat("Overlapped", len(overlapped))
        })
    ],
    how="vertical"
)

combined_gtf = combined_gtf\
    .join(dataset_label, on="transcript_id", how="left")
```

# Get Novel Exons

```{python}
#| label: get-exon_status
combined_gtf = combined_gtf\
    .join(gencode_V39.unique(["seqname", "start", "end", "strand"])[["seqname", "start", "end", "strand", "source"]], on=["seqname", "start", "end", "strand"], how="left")\
    .with_columns(
        pl.when(pl.col("source").is_null()).then(pl.lit("NOVEL")).otherwise(pl.lit("KNOWN")).alias("exon_status")
    ).drop("source")
```

```{python}
#| label: write_combined_gtf
combined_gtf.write_csv("transcript_vis_app/shiny.csv")
```

# Abundance

```{python}
pl.concat(
    [
        pl.DataFrame((lr_bulk.X.T).toarray(), schema=lr_bulk.obs_names.to_list()), 
        lr_bulk.var_names.to_frame()
    ],
    how="horizontal"
    )\
    .join(lr_bulk.var["pbid", "associated_transcript"], on="pbid", how="left")\
    .with_columns(
        pl.when(pl.col("associated_transcript")=="novel").then(pl.col("pbid")).otherwise(pl.col("associated_transcript"))
    ).drop("associated_transcript")\
    .join(PBID_to_TALON_ID.rename({"transcript_id": "pbid"}), on="pbid", how="left")\
    .with_columns(
        pl.when(pl.col("ref_id").is_null()).then(pl.col("pbid")).otherwise(pl.col("ref_id"))
    ).drop("ref_id")\
    .group_by("pbid").sum()\
    .with_columns(
        (cs.numeric() / cs.numeric().sum() * 1e6 + 1).log(base=2)
    )\
    .transpose(column_names="pbid", include_header=True, header_name="sampleID")\
    .with_columns(
        pl.col("sampleID").map_elements(lambda s: s.split("_")[0], return_dtype=pl.String)
    )\
    .group_by("sampleID").mean()\
    .transpose(column_names="sampleID", include_header=True, header_name="transcript_id")\
    .write_csv("transcript_vis_app/pbid_abundance.csv")
```

```{python}
pl.read_csv("/Users/xunuo/projects/Dev_Brain_IsoSeq/data/cp_vz_0.75_min_7_recovery_talon_abundance_filtered.tsv", separator="\t")\
    .rename({"annot_transcript_id": "transcript_id"})\
    .join(TALON_ID_to_GENCODE_V39, on="transcript_id", how="left")\
    .with_columns(
        transcript_id = pl.when(pl.col("ref_id").is_null()).then(pl.col("transcript_id")).otherwise(pl.col("ref_id"))
    ).drop("ref_id")\
    .group_by("transcript_id").sum()\
    .with_columns(
        (cs.ends_with("CP") / cs.ends_with("CP").sum() * 1e6 + 1).log(base=2),
        (cs.ends_with("VZ") / cs.ends_with("VZ").sum() * 1e6 + 1 ).log(base=2)
    )\
    .select(
        pl.col("transcript_id"),
        CP_mean = pl.mean_horizontal(cs.ends_with("CP")),      
        VZ_mean = pl.mean_horizontal(cs.ends_with("VZ"))
    )\
    .filter(pl.col("transcript_id").is_in(combined_gtf["transcript_id"]))\
    .write_csv("transcript_vis_app/talon_abundance.csv")
```