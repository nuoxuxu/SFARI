# Preparation

```{python}
#| label: import-python
import polars as pl
from src.single_cell import SingleCell
from src.utils import read_gtf
import numpy as np
import polars.selectors as cs
```

```{python}
#| label: read-gencode_V39

gencode_V39 = read_gtf("/Users/xunuo/Genomic_references/GENCODE/gencode.v39.annotation.gtf", ["gene_name", "transcript_id", "gene_id"]).filter(pl.col("feature")=="exon")
```

```{python}
#| label: define-functions

def read_refmap(file):
    out = pl.read_csv(file, separator="\t")\
    .filter(pl.col("class_code")=="=")\
    .with_columns(
        pl.col("qry_id_list").str.split(",").map_elements(lambda s: [e.split("|")[1] for e in s], return_dtype=pl.List(pl.String)).alias("qry_id_list"))\
    .explode("qry_id_list")\
    .select(["qry_id_list", "ref_id"])\
    .rename({"qry_id_list": "transcript_id"})
    return out
```

# Preprocess TALON GTF

Since `talon.gtf` is in hg19, we need to lift it over to hg38

```{bash}
#| label: liftover

curl -L https://hgdownload.cse.ucsc.edu/goldenpath/hg19/liftOver/hg19ToHg38.over.chain.gz -o hg19ToHg38.over.chain.gz

CrossMap gff proc/hg19ToHg38.over.chain /Users/xunuo/projects/Dev_Brain_IsoSeq/data/cp_vz_0.75_min_7_recovery_talon.gtf proc/cp_vz_0.75_min_7_recovery_talon_hg38.gtf
```

Since `talon.gtf` is mapped to Gencode v33, we need to get a mapping from TALON transcript IDs to ENST IDs in Gencode v39

```{bash}
#| label: gffcompare

gffcompare -r /Users/xunuo/Genomic_references/GENCODE/gencode.v39.annotation.gtf proc/cp_vz_0.75_min_7_recovery_talon_hg38.gtf -o proc/TALON_GENCODE_V39
```

```{python}
#| label: TALON_ID_to_GENCODE_V39

TALON_ID_to_GENCODE_V39 = read_refmap("proc/TALON_GENCODE_V39.cp_vz_0.75_min_7_recovery_talon_hg38.gtf.refmap")
```

Since the mappping between transcript_id and ref_id is not injective, we need to identify transcripts that are not uniquely mapped to a ref_id and remove them. It turns out that most transcript_id that are not uniquely mapped to a ref_id at least maps to one ref_id that matches transcript_id exactly (the version numbers could be different), so we decided to discard the other match and treat these cases as one-to-one. The transcript_id that are mapped to more than one ref_id where none of the matching ref_id matches the transcript_id are removed.

```{python}
#| label: n_transcripts_removed

n_transcripts_removed = TALON_ID_to_GENCODE_V39\
    .filter(pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39.group_by("transcript_id").len().filter(pl.col("len")>1)["transcript_id"]))\
    .with_columns(
        pl.col("transcript_id").map_elements(lambda s: s.split("_")[0].split(".")[0], return_dtype=pl.String),
        pl.col("ref_id").map_elements(lambda s: s.split(".")[0], return_dtype=pl.String)
    )\
    .with_columns(
        is_same = (pl.col("transcript_id") == pl.col("ref_id"))
    )\
    .with_columns(
        pl.col("is_same").cast(pl.Int16)
    )\
    .group_by("transcript_id").agg(
        pl.col("is_same").sum().alias("is_same")
    ).filter(pl.col("is_same")==0).shape[0]

print(f"{n_transcripts_removed} transcripts will be removed because they are not uniquely mapped to a ref_id and none of the matching ref_id matches the transcript_id")    
```

Make sure TALON_ID_to_GENCODE_V39 is injective

```{python}
#| label: keep-only-one-to-one-mappings-TALON_ID_to_GENCODE_V39

one_to_one = TALON_ID_to_GENCODE_V39\
    .filter(pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39.group_by("transcript_id").len().filter(pl.col("len")==1)["transcript_id"]))

one_to_many = TALON_ID_to_GENCODE_V39\
    .filter(pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39.group_by("transcript_id").len().filter(pl.col("len")>1)["transcript_id"]))\
    .with_columns(
        is_same = (pl.col("transcript_id").map_elements(lambda s: s.split("_")[0].split(".")[0], return_dtype=pl.String) ==  pl.col("ref_id").map_elements(lambda s: s.split(".")[0], return_dtype=pl.String))
    )\
    .with_columns(
        pl.col("is_same").cast(pl.Int16)
    )\
    .filter(
        pl.col("is_same") == 1
    ).drop("is_same")

TALON_ID_to_GENCODE_V39 = pl.concat([one_to_one, one_to_many], how="vertical")
```

```{python}
#| label: import-TALON_gtf

TALON_gtf = read_gtf("proc/cp_vz_0.75_min_7_recovery_talon_hg38.gtf", ["gene_name", "transcript_id", "gene_id"])\
    .filter(
        pl.col("feature")=="exon",
        pl.col("gene_name").str.starts_with("TALON").not_()
    )
```

```{python}
#| label: write-TALON_not_in_GENCODE

TALON_gtf\
    .filter(
        (pl.col("transcript_id").str.starts_with("TALON")) & (pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39["transcript_id"]).not_())
    )\
    .with_columns(
        attributes = pl.lit('gene_name "') + pl.col("gene_name") + pl.lit('"; transcript_id "') + pl.col("transcript_id") + pl.lit('"; gene_id "') + pl.col("gene_id") + pl.lit('";')
    )\
    .drop("gene_name", "transcript_id", "gene_id")\
    .write_csv("proc/TALON_not_in_GENCODE.gtf", separator="\t", quote_style="never", include_header=False)    
```

# Preprocess SFARI GTF

```{python}
#| label: import-SFARI_gff

lr_bulk = SingleCell("results/long_read/pbid_filtered.h5ad")

SFARI_gff = read_gtf(
    "/Users/xunuo/projects/SFARI/results/long_read/merged_collapsed.sorted.gff", 
    ["transcript_id"])\
    .rename({"transcript_id": "pbid"})\
    .filter(pl.col("feature")=="exon")\
    .join(lr_bulk.var["pbid", "associated_transcript", "associated_gene"], on="pbid", how="left")\
    .filter(pl.col("associated_gene").cast(pl.String).str.starts_with("novelGene").not_())\
    .with_columns(
        pl.col("associated_transcript").cast(pl.String)
        )
```

```{python}
#| label: write-SFARI_not_in_GENCODE

SFARI_gff\
    .filter(pl.col("associated_transcript") == "novel")\
    .with_columns(
        attributes = pl.lit('gene_id "') + pl.col("associated_gene") + pl.lit('"; transcript_id "') + pl.col("pbid") + pl.lit('";')
    )\
    .drop("pbid", "associated_gene", "associated_transcript")\
    .write_csv("proc/SFARI_not_in_GENCODE.gtf", separator="\t", quote_style="never", include_header=False)
```

Get a mapping from SFARI pbid to TALON transcript ID

```{bash}
#| label: gffcompare

gffcompare -r proc/TALON_not_in_GENCODE.gtf proc/SFARI_not_in_GENCODE.gtf -o proc/SFARI_TALON
```

```{python}
#| label: get-PBID_to_TALON_ID

PBID_to_TALON_ID = read_refmap("proc/SFARI_TALON.SFARI_not_in_GENCODE.gtf.refmap")
```

```{python}
#| label: get-combined_gtf

GENCODE_ID_union = np.union1d(
    TALON_ID_to_GENCODE_V39["ref_id"].unique().to_numpy().reshape(-1),
    SFARI_gff.filter(pl.col("associated_transcript").is_in(["novel"]).not_()).select(["associated_transcript"]).unique().to_numpy().reshape(-1)
    )

GENCODE_part = gencode_V39\
    .filter(pl.col("transcript_id").is_in(GENCODE_ID_union))\
    .select(
        [
            "seqname",
            "start",
            "end",
            "strand",
            "gene_name",
            "transcript_id"
        ]
    )

# TALON IDs that are not in GENCODE

TALON_part = TALON_gtf.filter((pl.col("transcript_id").str.starts_with("TALON")) & (pl.col("transcript_id").is_in(TALON_ID_to_GENCODE_V39["transcript_id"]).not_()))\
    .select(
        [
            "seqname",
            "start",
            "end",
            "strand",
            "gene_name",
            "transcript_id"
        ]
    )

# novel PBIDs that are not in TALON

SFARI_part = SFARI_gff\
    .filter(pl.col("associated_transcript").is_in(["novel"]))\
    .filter(pl.col("pbid").is_in(PBID_to_TALON_ID["pbid"]).not_())\
    .select(
    [
        "seqname",
        "start",
        "end",
        "strand",
        "associated_gene",
        "pbid"
    ])\
    .rename({"associated_gene": "gene_name", "pbid": "transcript_id"})\
    .cast({"gene_name": pl.String})

combined_gtf = pl.concat([GENCODE_part, TALON_part, SFARI_part], how="vertical")    
```

```{python}
#| label: add-dataset-label

GENCODE_unique_to_TALON = np.setdiff1d(
    TALON_ID_to_GENCODE_V39["ref_id"].unique().to_numpy().reshape(-1),
    SFARI_gff.filter(pl.col("associated_transcript").is_in(["novel"]).not_()).select(["associated_transcript"]).unique().to_numpy().reshape(-1)
)

GENCODE_unique_to_SFARI = np.setdiff1d(
    SFARI_gff.filter(pl.col("associated_transcript").is_in(["novel"]).not_()).select(["associated_transcript"]).unique().to_numpy().reshape(-1),
    TALON_ID_to_GENCODE_V39["ref_id"].unique().to_numpy().reshape(-1)
)

GENCODE_overlapped = np.intersect1d(
    TALON_ID_to_GENCODE_V39["ref_id"].unique().to_numpy().reshape(-1),
    SFARI_gff.filter(pl.col("associated_transcript").is_in(["novel"]).not_()).select(["associated_transcript"]).unique().to_numpy().reshape(-1)
)

TALON_transcripts = TALON_gtf\
    .filter(pl.col("transcript_id").str.starts_with("TALON"))\
    .filter(pl.col("transcript_id").is_in(PBID_to_TALON_ID["ref_id"]).not_())["transcript_id"].unique().to_numpy().reshape(-1)

SFARI_transcripts = SFARI_gff\
    .filter(pl.col("associated_transcript").is_in(["novel"]))\
    .filter(pl.col("pbid").is_in(PBID_to_TALON_ID["pbid"]).not_())["pbid"].unique().to_numpy().reshape(-1)

unique_to_TALON = np.union1d(GENCODE_unique_to_TALON, TALON_transcripts)

unique_to_SFARI = np.union1d(GENCODE_unique_to_SFARI, SFARI_transcripts)

overlapped = np.hstack([GENCODE_overlapped, PBID_to_TALON_ID["ref_id"].unique().to_numpy().reshape(-1)])

dataset_label = pl.concat(
    [
        pl.DataFrame({
            "transcript_id": unique_to_TALON,
            "dataset": np.repeat("Patowary et al.", len(unique_to_TALON))
        }),
        pl.DataFrame({
            "transcript_id": unique_to_SFARI,
            "dataset": np.repeat("SFARI", len(unique_to_SFARI))
        }),
        pl.DataFrame({
            "transcript_id": overlapped,
            "dataset": np.repeat("Overlapped", len(overlapped))
        })
    ],
    how="vertical"
)

combined_gtf = combined_gtf\
    .join(dataset_label, on="transcript_id", how="left")
```

# Get Novel Exons

```{python}
#| label: get-exon_status
combined_gtf = combined_gtf\
    .join(gencode_V39.unique(["seqname", "start", "end", "strand"])[["seqname", "start", "end", "strand", "source"]], on=["seqname", "start", "end", "strand"], how="left")\
    .with_columns(
        pl.when(pl.col("source").is_null()).then(pl.lit("NOVEL")).otherwise(pl.lit("KNOWN")).alias("exon_status")
    ).drop("source")
```

```{python}
#| label: write_combined_gtf
combined_gtf.write_csv("transcript_vis_app/shiny.csv")
```

# Abundance

```{python}
pl.concat(
    [
        pl.DataFrame((lr_bulk.X.T).toarray(), schema=lr_bulk.obs_names.to_list()), 
        lr_bulk.var_names.to_frame()
    ],
    how="horizontal"
    )\
    .join(lr_bulk.var["pbid", "associated_transcript"], on="pbid", how="left")\
    .with_columns(
        pl.when(pl.col("associated_transcript")=="novel").then(pl.col("pbid")).otherwise(pl.col("associated_transcript"))
    ).drop("associated_transcript")\
    .join(PBID_to_TALON_ID.rename({"transcript_id": "pbid"}), on="pbid", how="left")\
    .with_columns(
        pl.when(pl.col("ref_id").is_null()).then(pl.col("pbid")).otherwise(pl.col("ref_id"))
    ).drop("ref_id")\
    .group_by("pbid").sum()\
    .with_columns(
        (cs.numeric() / cs.numeric().sum() * 1e6 + 1).log(base=2)
    )\
    .transpose(column_names="pbid", include_header=True, header_name="sampleID")\
    .with_columns(
        pl.col("sampleID").map_elements(lambda s: s.split("_")[0], return_dtype=pl.String)
    )\
    .group_by("sampleID").mean()\
    .transpose(column_names="sampleID", include_header=True, header_name="transcript_id")\
    .write_csv("transcript_vis_app/pbid_abundance.csv")
```

```{python}
pl.read_csv("/Users/xunuo/projects/Dev_Brain_IsoSeq/data/cp_vz_0.75_min_7_recovery_talon_abundance_filtered.tsv", separator="\t")\
    .rename({"annot_transcript_id": "transcript_id"})\
    .join(TALON_ID_to_GENCODE_V39, on="transcript_id", how="left")\
    .with_columns(
        transcript_id = pl.when(pl.col("ref_id").is_null()).then(pl.col("transcript_id")).otherwise(pl.col("ref_id"))
    ).drop("ref_id")\
    .group_by("transcript_id").sum()\
    .with_columns(
        (cs.ends_with("CP") / cs.ends_with("CP").sum() * 1e6 + 1).log(base=2),
        (cs.ends_with("VZ") / cs.ends_with("VZ").sum() * 1e6 + 1 ).log(base=2)
    )\
    .select(
        pl.col("transcript_id"),
        CP_mean = pl.mean_horizontal(cs.ends_with("CP")),      
        VZ_mean = pl.mean_horizontal(cs.ends_with("VZ"))
    )\
    .filter(pl.col("transcript_id").is_in(combined_gtf["transcript_id"]))\
    .write_csv("transcript_vis_app/talon_abundance.csv")
```

# Processing GENCODE gtf

```{python}
#| label: load-ENST-in-gencode.v39.pc_translations.f
from Bio import SeqIO
from collections import defaultdict
def read_fasta(fasta_file):
    seqs = defaultdict()
    for rec in SeqIO.parse(fasta_file, 'fasta'):
        if rec.id.startswith("ENSP"):            
            seqs[rec.id.split("|")[1]] = str(rec.seq)
        elif rec.id.count("p")==1:
            seqs[rec.id.rsplit(".", 1)[0]] = str(rec.seq)
        else:
            seqs[rec.id] = str(rec.seq)
    return seqs
gencode_v39_pc = read_fasta("/Users/xunuo/Genomic_references/GENCODE/gencode.v39.pc_translations.fa")
```

```{python}
#| label: filter-gencode_gtf
gencode_gtf = read_gtf(
    "/Users/xunuo/Genomic_references/GENCODE/gencode.v39.annotation.gtf",
    attributes = ["gene_name", "transcript_id", "transcript_type"]
    )\
    .filter(
        pl.col("feature").is_in(["exon", "CDS"]),
        pl.col("gene_name").is_in(CDS_gtf["gene_name"].unique()),
        pl.col("transcript_id").is_in(list(gencode_v39_pc.keys()))
        )\
    ["seqname", "feature", "start", "end", "strand", "gene_name", "transcript_id", "transcript_type"]
```

```{python}
#| label: write-gencode_gtf
gencode_gtf.write_csv("transcript_vis_app/GENCODE_v39.csv")
```

# Processing Peptides gtf

```{python}
from src.ryp import r, to_r
```

```{r}
library(dplyr)
library(GenomicFeatures)
library(GenomicAlignments)
library(rtracklayer)
library(readr)
```

```{r}
#| label: splice-junction-peptides
peptide_SJ <- makeTxDbFromGFF("nextflow_results/SFARI_peptides.gtf") %>%
    intronsByTranscript(use.names=TRUE)
peptide_SJ <- peptide_SJ[lengths(peptide_SJ) != 0] %>%
    unlist()

GENCODE_SJ <- makeTxDbFromGFF(paste0(Sys.getenv("GENOMIC_DATA_DIR"), "GENCODE/gencode.v39.annotation.gtf")) %>%
    intronsByTranscript(use.names=TRUE) %>%
    unlist()

peptide_SJ_not_in_GENCODE <- peptide_SJ[!(seq_along(peptide_SJ) %in% queryHits(findOverlaps(peptide_SJ, GENCODE_SJ, type = "equal")))]

SFARI_SJ <- makeTxDbFromGFF("nextflow_results/transcripts_filtered.fasta.transdecoder.genome.gff3.gtf") %>% 
    intronsByTranscript(use.names=TRUE)
SFARI_SJ <- SFARI_SJ[lengths(SFARI_SJ) != 0] %>%
    unlist()

pbid_containing_novel_SJs <- SFARI_SJ[unique(subjectHits(findOverlaps(peptide_SJ_not_in_GENCODE, SFARI_SJ, type="equal")))] %>%
    names() %>%
    unique()
```

```{r}
#| label: mono-exonic-peptides
peptide_exon <- makeTxDbFromGFF("nextflow_results/SFARI_peptides.gtf") %>%
    exonsBy(use.names = TRUE, by = "tx")
peptide_exon <- peptide_exon[lengths(peptide_exon) == 1]

GENCODE_exon <- makeTxDbFromGFF(paste0(Sys.getenv("GENOMIC_DATA_DIR"), "GENCODE/gencode.v39.annotation.gtf")) %>%
    exonsBy(by = "tx", use.names=TRUE)

peptide_exon_not_in_GENCODE <- peptide_exon[!(seq_along(peptide_exon) %in% queryHits(findSpliceOverlaps(peptide_exon, GENCODE_exon)))] %>% unlist()

SFARI_CDS <- makeTxDbFromGFF("nextflow_results/transcripts_filtered.fasta.transdecoder.genome.gff3.gtf") %>% 
    cdsBy(by = "tx", use.names=TRUE)

idx <- findSpliceOverlaps(peptide_exon[!(seq_along(peptide_exon) %in% queryHits(findSpliceOverlaps(peptide_exon, GENCODE_exon)))], SFARI_CDS) %>%
    subjectHits()

pbid_containing_novel_exons <- names(SFARI_CDS[idx])
```

```{r}
#| label: write-SFARI_peptides
SFARI_peptides <- as.data.frame(import.gff("nextflow_results/SFARI_peptides.gtf"))
SFARI_peptides <- SFARI_peptides %>%
    mutate(
        type = case_when(
            transcript_id %in% names(peptide_exon) ~ "mono-exonic",
            transcript_id %in% names(peptide_SJ) ~ "splice-junction"
        ),
        novelty = case_when(
            transcript_id %in% c(names(peptide_exon_not_in_GENCODE), names(peptide_SJ_not_in_GENCODE)) ~ "novel",
            .default = "known"
        )
    )
SFARI_peptides[c("seqnames", "start", "end", "strand", "gene_name", "transcript_id", "type", "novelty")] %>%
    write.csv("transcript_vis_app/SFARI_peptides.csv")
```

# Processing SFARI CDS GTF

```{python}
#| label: import-genome-gff3-gtf
CDS_gtf  = read_gtf(
    "nextflow_results/transcripts_filtered.fasta.transdecoder.genome.gff3.gtf",
    attributes = ["transcript_id", "gene_id"]
    )\
    .filter(
        pl.col("feature")!="transcript",
        pl.col("feature") == "CDS"
        )\
    ["seqname", "feature", "start", "end", "strand", "gene_id", "transcript_id"]


protein_classification = pl.read_csv("nextflow_results/SFARI_unfiltered.protein_classification.tsv", separator = "\t").rename({"pb": "transcript_id"})["transcript_id", "pr_gene", "protein_classification_base"]

gene_id_to_gene_name = read_gtf(paste0(Sys.getenv("GENCODE/gencode.v39.annotation.gtf")), attributes = ["gene_name", "gene_id"]).unique("gene_id")["gene_name", "gene_id"]
```

```{python}
#| label: add-protein_classification_base-and-gene_name
CDS_gtf = CDS_gtf\
    .join(
        protein_classification,
        on = "transcript_id",
        how = "left"
    )\
    .join(
        gene_id_to_gene_name.rename({"gene_id": "pr_gene"}),
        on = "pr_gene",
        how = "left"
    )["seqname", "feature", "start", "end", "strand", "gene_name", "transcript_id", "protein_classification_base"]
to_r(CDS_gtf, "genome_gff3_gtf")
```

```{r}
#| label: write-genome_gff3_gtf
genome_gff3_gtf <- genome_gff3_gtf %>%
    mutate(
        containing_novel_spl = case_when(
            transcript_id %in% c(pbid_containing_novel_SJs, pbid_containing_novel_exons) ~ TRUE,
            .default = FALSE
        )
    )

genome_gff3_gtf %>% write.csv("transcript_vis_app/genome_gff3_gtf.csv")
```